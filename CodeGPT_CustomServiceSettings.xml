<application>
  <component name="CodeGPT_CustomServiceSettings">
    <option name="chatCompletionSettings">
      <CustomServiceChatCompletionSettingsState>
        <option name="body" value="{&quot;stream&quot;:true,&quot;model&quot;:&quot;qwen:7b&quot;,&quot;messages&quot;:&quot;$OPENAI_MESSAGES&quot;,&quot;temperature&quot;:0.1}" />
        <option name="headers">
          <map>
            <entry key="Content-Type" value="application/json" />
            <entry key="X-LLM-Application-Tag" value="codegpt" />
          </map>
        </option>
        <option name="url" value="http://localhost:11434/v1/chat/completions" />
      </CustomServiceChatCompletionSettingsState>
    </option>
    <option name="template" value="Ollama" />
  </component>
</application>